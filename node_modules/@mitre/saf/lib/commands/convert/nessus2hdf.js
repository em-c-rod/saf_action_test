"use strict";
Object.defineProperty(exports, "__esModule", { value: true });
const tslib_1 = require("tslib");
const command_1 = require("@oclif/command");
const fs_1 = tslib_1.__importDefault(require("fs"));
const hdf_converters_1 = require("@mitre/hdf-converters");
const lodash_1 = tslib_1.__importDefault(require("lodash"));
const global_1 = require("../../utils/global");
class Nessus2HDF extends command_1.Command {
    async run() {
        const { flags } = this.parse(Nessus2HDF);
        const converter = new hdf_converters_1.NessusResults(fs_1.default.readFileSync(flags.input, 'utf-8'));
        const result = converter.toHdf();
        if (Array.isArray(result)) {
            for (const element of result) {
                fs_1.default.writeFileSync(`${flags.output.replace(/.json/gi, '')}-${lodash_1.default.get(element, 'platform.target_id')}.json`, JSON.stringify(element));
            }
        }
        else {
            fs_1.default.writeFileSync(`${(0, global_1.checkSuffix)(flags.output)}`, JSON.stringify(result));
        }
    }
}
exports.default = Nessus2HDF;
Nessus2HDF.usage = 'convet:nessus2hdf -i, --input=XML -o, --output=OUTPUT';
Nessus2HDF.description = "Translate a Nessus XML results file into a Heimdall Data Format JSON file\nThe current iteration maps all plugin families except 'Policy Compliance'\nA separate HDF JSON is generated for each host reported in the Nessus Report.";
Nessus2HDF.examples = ['saf convert:nessus2hdf -i nessus_results.xml -o output-hdf-name.json'];
Nessus2HDF.flags = {
    help: command_1.flags.help({ char: 'h' }),
    input: command_1.flags.string({ char: 'i', required: true }),
    output: command_1.flags.string({ char: 'o', required: true }),
};
